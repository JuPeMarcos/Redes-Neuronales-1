{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc963e1494118a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:43:29.498236300Z",
     "start_time": "2024-02-15T16:43:27.533009800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importación de bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import display\n",
    "\n",
    "# Carga del conjunto de datos de vino tinto desde un archivo CSV\n",
    "red_wine = pd.read_csv('csv/red-wine.csv')\n",
    "\n",
    "# Crear una instancia de StandardScaler para normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalizar el conjunto de datos excluyendo la columna 'quality'\n",
    "red_wine_normalized = pd.DataFrame(scaler.fit_transform(red_wine.drop('quality', axis=1)), columns=red_wine.columns[:-1])\n",
    "red_wine_normalized['quality'] = red_wine['quality']\n",
    "\n",
    "# Crear conjuntos de entrenamiento y validación después de la normalización\n",
    "df_train_normalized = red_wine_normalized.sample(frac=0.7, random_state=0)\n",
    "df_valid_normalized = red_wine_normalized.drop(df_train_normalized.index)\n",
    "display(df_train_normalized.head(4))\n",
    "\n",
    "# Separar características y objetivo para el conjunto de entrenamiento normalizado\n",
    "X_train_normalized = df_train_normalized.drop('quality', axis=1)\n",
    "X_valid_normalized = df_valid_normalized.drop('quality', axis=1)\n",
    "y_train_normalized = df_train_normalized['quality']\n",
    "y_valid_normalized = df_valid_normalized['quality']\n",
    "\n",
    "# Imprime la forma (número de filas y columnas) de X_train_normalized\n",
    "print(X_train_normalized.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34941e780d08c75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:43:38.196895300Z",
     "start_time": "2024-02-15T16:43:29.534477200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importación de TensorFlow y Keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Creación del modelo de red neuronal para datos normalizados\n",
    "model_normalized = keras.Sequential([\n",
    "    # Capa densa con 120 neuronas, función de activación ReLU y entrada de forma [11]\n",
    "    layers.Dense(120, activation='relu', input_shape=[11]),\n",
    "    \n",
    "    # Capa densa con 1 neurona (salida)\n",
    "    layers.Dense(1),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf3b32ca6ce495b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:43:38.363731400Z",
     "start_time": "2024-02-15T16:43:38.200875200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compilación del modelo normalizado con el optimizador 'adam' y la función de pérdida 'mae' (Mean Absolute Error)\n",
    "model_normalized.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfba747d0310520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:43:40.444976Z",
     "start_time": "2024-02-15T16:43:38.347358900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Entrenamiento del modelo normalizado con los datos de entrenamiento y validación\n",
    "# Se utiliza X_train_normalized y y_train_normalized para el entrenamiento,\n",
    "# y X_valid_normalized e y_valid_normalized para la validación\n",
    "# Se especifica el tamaño del lote (batch_size) como 256 y el número de épocas como 10\n",
    "history_normalized = model_normalized.fit(\n",
    "    X_train_normalized, y_train_normalized,\n",
    "    validation_data=(X_valid_normalized, y_valid_normalized),\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac6bf85d5fc0b3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:43:41.457026100Z",
     "start_time": "2024-02-15T16:43:40.448425700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importar la biblioteca Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Convertir el historial de entrenamiento normalizado a un DataFrame\n",
    "history_df_normalized = pd.DataFrame(history_normalized.history)\n",
    "\n",
    "# Utilizar el método de trazado nativo de Pandas para visualizar la pérdida a lo largo de las épocas\n",
    "history_df_normalized['loss'].plot();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee36d86791d9cd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:46:42.721145Z",
     "start_time": "2024-02-15T16:46:42.646900100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluación del modelo normalizado en el conjunto de validación\n",
    "eval_result_normalized = model_normalized.evaluate(X_valid_normalized, y_valid_normalized)\n",
    "\n",
    "# Imprime la pérdida en los datos de validación normalizados\n",
    "print(f\"Loss en datos de validación: {eval_result_normalized}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
